{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3fcec7e1-48c9-47ee-b2b3-9a83aeb3ab58",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fatal: destination path 'Neutron_Reflect' already exists and is not an empty directory.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "!git clone https://github.com/miguel-fc/Neutron_Reflect.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "483dccd5-6554-4fef-937e-1ec0d64990d1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/pscratch/sd/q/qubri000/Neutron_Reflect\n"
     ]
    }
   ],
   "source": [
    "cd Neutron_Reflect/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3f65f831-02c4-4394-8ecf-079fa84968be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pip in /global/u1/q/qubri000/.local/perlmutter/pytorch2.0.1/lib/python3.9/site-packages (23.3.2)\n",
      "\u001b[33mDEPRECATION: pytorch-lightning 1.6.5 has a non-standard dependency specifier torch>=1.8.*. pip 24.0 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of pytorch-lightning or contact the author to suggest that they release a version with a conforming dependency specifiers. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5e779cf8-dd4e-4bec-aa96-7a13d0e13827",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: gdown in /global/u1/q/qubri000/.local/perlmutter/pytorch2.0.1/lib/python3.9/site-packages (4.7.1)\n",
      "Requirement already satisfied: filelock in /global/common/software/nersc/pm-2022q4/sw/pytorch/2.0.1/lib/python3.9/site-packages (from gdown) (3.12.0)\n",
      "Requirement already satisfied: requests[socks] in /global/common/software/nersc/pm-2022q4/sw/pytorch/2.0.1/lib/python3.9/site-packages (from gdown) (2.29.0)\n",
      "Requirement already satisfied: six in /global/common/software/nersc/pm-2022q4/sw/pytorch/2.0.1/lib/python3.9/site-packages (from gdown) (1.16.0)\n",
      "Requirement already satisfied: tqdm in /global/common/software/nersc/pm-2022q4/sw/pytorch/2.0.1/lib/python3.9/site-packages (from gdown) (4.65.0)\n",
      "Requirement already satisfied: beautifulsoup4 in /global/common/software/nersc/pm-2022q4/sw/pytorch/2.0.1/lib/python3.9/site-packages (from gdown) (4.12.2)\n",
      "Requirement already satisfied: soupsieve>1.2 in /global/common/software/nersc/pm-2022q4/sw/pytorch/2.0.1/lib/python3.9/site-packages (from beautifulsoup4->gdown) (2.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /global/common/software/nersc/pm-2022q4/sw/pytorch/2.0.1/lib/python3.9/site-packages (from requests[socks]->gdown) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /global/common/software/nersc/pm-2022q4/sw/pytorch/2.0.1/lib/python3.9/site-packages (from requests[socks]->gdown) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /global/common/software/nersc/pm-2022q4/sw/pytorch/2.0.1/lib/python3.9/site-packages (from requests[socks]->gdown) (1.26.15)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /global/common/software/nersc/pm-2022q4/sw/pytorch/2.0.1/lib/python3.9/site-packages (from requests[socks]->gdown) (2022.12.7)\n",
      "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /global/common/software/nersc/pm-2022q4/sw/pytorch/2.0.1/lib/python3.9/site-packages (from requests[socks]->gdown) (1.7.1)\n",
      "\u001b[33mDEPRECATION: pytorch-lightning 1.6.5 has a non-standard dependency specifier torch>=1.8.*. pip 24.0 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of pytorch-lightning or contact the author to suggest that they release a version with a conforming dependency specifiers. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install gdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c89da939-70ee-4038-b9f0-f5e872c004d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: seaborn in /global/u1/q/qubri000/.local/perlmutter/pytorch2.0.1/lib/python3.9/site-packages (0.13.0)\n",
      "Requirement already satisfied: numpy!=1.24.0,>=1.20 in /global/common/software/nersc/pm-2022q4/sw/pytorch/2.0.1/lib/python3.9/site-packages (from seaborn) (1.24.3)\n",
      "Requirement already satisfied: pandas>=1.2 in /global/common/software/nersc/pm-2022q4/sw/pytorch/2.0.1/lib/python3.9/site-packages (from seaborn) (1.5.3)\n",
      "Requirement already satisfied: matplotlib!=3.6.1,>=3.3 in /global/common/software/nersc/pm-2022q4/sw/pytorch/2.0.1/lib/python3.9/site-packages (from seaborn) (3.7.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /global/common/software/nersc/pm-2022q4/sw/pytorch/2.0.1/lib/python3.9/site-packages (from matplotlib!=3.6.1,>=3.3->seaborn) (1.0.5)\n",
      "Requirement already satisfied: cycler>=0.10 in /global/common/software/nersc/pm-2022q4/sw/pytorch/2.0.1/lib/python3.9/site-packages (from matplotlib!=3.6.1,>=3.3->seaborn) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /global/common/software/nersc/pm-2022q4/sw/pytorch/2.0.1/lib/python3.9/site-packages (from matplotlib!=3.6.1,>=3.3->seaborn) (4.25.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /global/common/software/nersc/pm-2022q4/sw/pytorch/2.0.1/lib/python3.9/site-packages (from matplotlib!=3.6.1,>=3.3->seaborn) (1.4.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /global/common/software/nersc/pm-2022q4/sw/pytorch/2.0.1/lib/python3.9/site-packages (from matplotlib!=3.6.1,>=3.3->seaborn) (23.0)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /global/common/software/nersc/pm-2022q4/sw/pytorch/2.0.1/lib/python3.9/site-packages (from matplotlib!=3.6.1,>=3.3->seaborn) (9.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /global/common/software/nersc/pm-2022q4/sw/pytorch/2.0.1/lib/python3.9/site-packages (from matplotlib!=3.6.1,>=3.3->seaborn) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /global/common/software/nersc/pm-2022q4/sw/pytorch/2.0.1/lib/python3.9/site-packages (from matplotlib!=3.6.1,>=3.3->seaborn) (2.8.2)\n",
      "Requirement already satisfied: importlib-resources>=3.2.0 in /global/common/software/nersc/pm-2022q4/sw/pytorch/2.0.1/lib/python3.9/site-packages (from matplotlib!=3.6.1,>=3.3->seaborn) (5.2.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /global/common/software/nersc/pm-2022q4/sw/pytorch/2.0.1/lib/python3.9/site-packages (from pandas>=1.2->seaborn) (2022.7)\n",
      "Requirement already satisfied: zipp>=3.1.0 in /global/common/software/nersc/pm-2022q4/sw/pytorch/2.0.1/lib/python3.9/site-packages (from importlib-resources>=3.2.0->matplotlib!=3.6.1,>=3.3->seaborn) (3.11.0)\n",
      "Requirement already satisfied: six>=1.5 in /global/common/software/nersc/pm-2022q4/sw/pytorch/2.0.1/lib/python3.9/site-packages (from python-dateutil>=2.7->matplotlib!=3.6.1,>=3.3->seaborn) (1.16.0)\n",
      "\u001b[33mDEPRECATION: pytorch-lightning 1.6.5 has a non-standard dependency specifier torch>=1.8.*. pip 24.0 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of pytorch-lightning or contact the author to suggest that they release a version with a conforming dependency specifiers. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1b02edc6-4f2f-4118-8ed3-eb5322b05ce5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: plotly in /global/u1/q/qubri000/.local/perlmutter/pytorch2.0.1/lib/python3.9/site-packages (5.18.0)\n",
      "Requirement already satisfied: tenacity>=6.2.0 in /global/u1/q/qubri000/.local/perlmutter/pytorch2.0.1/lib/python3.9/site-packages (from plotly) (8.2.3)\n",
      "Requirement already satisfied: packaging in /global/common/software/nersc/pm-2022q4/sw/pytorch/2.0.1/lib/python3.9/site-packages (from plotly) (23.0)\n",
      "\u001b[33mDEPRECATION: pytorch-lightning 1.6.5 has a non-standard dependency specifier torch>=1.8.*. pip 24.0 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of pytorch-lightning or contact the author to suggest that they release a version with a conforming dependency specifiers. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install plotly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "31100e48-c0ef-46af-b9cd-6c80108bfd44",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: gdown in /global/u1/q/qubri000/.local/perlmutter/pytorch2.0.1/lib/python3.9/site-packages (4.7.1)\n",
      "Requirement already satisfied: filelock in /global/common/software/nersc/pm-2022q4/sw/pytorch/2.0.1/lib/python3.9/site-packages (from gdown) (3.12.0)\n",
      "Requirement already satisfied: requests[socks] in /global/common/software/nersc/pm-2022q4/sw/pytorch/2.0.1/lib/python3.9/site-packages (from gdown) (2.29.0)\n",
      "Requirement already satisfied: six in /global/common/software/nersc/pm-2022q4/sw/pytorch/2.0.1/lib/python3.9/site-packages (from gdown) (1.16.0)\n",
      "Requirement already satisfied: tqdm in /global/common/software/nersc/pm-2022q4/sw/pytorch/2.0.1/lib/python3.9/site-packages (from gdown) (4.65.0)\n",
      "Requirement already satisfied: beautifulsoup4 in /global/common/software/nersc/pm-2022q4/sw/pytorch/2.0.1/lib/python3.9/site-packages (from gdown) (4.12.2)\n",
      "Requirement already satisfied: soupsieve>1.2 in /global/common/software/nersc/pm-2022q4/sw/pytorch/2.0.1/lib/python3.9/site-packages (from beautifulsoup4->gdown) (2.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /global/common/software/nersc/pm-2022q4/sw/pytorch/2.0.1/lib/python3.9/site-packages (from requests[socks]->gdown) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /global/common/software/nersc/pm-2022q4/sw/pytorch/2.0.1/lib/python3.9/site-packages (from requests[socks]->gdown) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /global/common/software/nersc/pm-2022q4/sw/pytorch/2.0.1/lib/python3.9/site-packages (from requests[socks]->gdown) (1.26.15)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /global/common/software/nersc/pm-2022q4/sw/pytorch/2.0.1/lib/python3.9/site-packages (from requests[socks]->gdown) (2022.12.7)\n",
      "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /global/common/software/nersc/pm-2022q4/sw/pytorch/2.0.1/lib/python3.9/site-packages (from requests[socks]->gdown) (1.7.1)\n",
      "\u001b[33mDEPRECATION: pytorch-lightning 1.6.5 has a non-standard dependency specifier torch>=1.8.*. pip 24.0 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of pytorch-lightning or contact the author to suggest that they release a version with a conforming dependency specifiers. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -U --no-cache-dir gdown --pre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a8a0de76-6079-4998-8a7d-7dba6fa661fc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#import files\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.datasets as datasets\n",
    "import numpy as np\n",
    "import data_preparation as dpre\n",
    "import io\n",
    "import os\n",
    "# import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.lines as mlines\n",
    "%matplotlib inline\n",
    "import seaborn as sea"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "adadc327-ff32-48e9-bec4-3d9bdf9cbf87",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#CNN structure\n",
    "\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self, num_layers):\n",
    "        super(CNN, self).__init__()\n",
    "        self.layers = nn.ModuleList()\n",
    "        addition = 255/num_layers\n",
    "        curr = 1\n",
    "        for hdim in range(num_layers-1):\n",
    "            self.layers.append(nn.Conv1d(int(curr+0.5), int(curr+addition+0.5),51,padding=25))\n",
    "            self.layers.append(nn.BatchNorm1d(int(curr+addition+0.5)))\n",
    "            self.layers.append(nn.ReLU(True))\n",
    "            curr += addition\n",
    "        self.layers.append(nn.Conv1d(int(curr+0.5), 256, 51, padding=25))\n",
    "        \n",
    "        self.linear1 = nn.Linear(256*308,900*2)\n",
    "    def forward(self, x):\n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "        x = x.reshape(x.shape[0], -1)\n",
    "        x = self.linear1(x)\n",
    "        x = x.reshape(-1, 2, 900)\n",
    "        return torch.sigmoid(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "796dc609-1ba8-445d-aefe-9877c15cc452",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Training function\n",
    "def fit(Model, device, dataloader, loss_fn, optim):\n",
    "    Model.train().to(device)\n",
    "    train_loss = []\n",
    "    for data,label in dataloader:\n",
    "        img = data\n",
    "        img = img.to(device)\n",
    "        label = label.to(device)\n",
    "        decoded_img = Model(img)\n",
    "        # print(decoded_img.shape)\n",
    "        # decoded_img = decoded_img.reshape(-1,2, 308)\n",
    "        loss = loss_fn(decoded_img, label)\n",
    "        optim.zero_grad()\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "        train_loss.append(loss.cpu().detach().numpy())\n",
    "        # print(label, \"hello\")\n",
    "    return np.mean(train_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "497a1381-dbbe-448e-98e7-176fa37ce09b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "### Valid function\n",
    "def val(Model, device, dataloader, loss_fn):\n",
    "    Model.eval().to(device)\n",
    "    with torch.no_grad(): \n",
    "        list_decoded_img = []\n",
    "        list_img = []\n",
    "        for  data, label in dataloader:\n",
    "            img = data\n",
    "            # img = img.view(img.size(0), -1).to(device) \n",
    "            # img = img[:,np.newaxis,:].to(device) \n",
    "            img = img.to(device) \n",
    "            label = label.to(device)\n",
    "            decoded_img = Model(img)\n",
    "            # decoded_img = decoded_img.reshape(-1,2, 308)\n",
    "            list_decoded_img.append(decoded_img.cpu())\n",
    "            list_img.append(label.cpu())\n",
    "        list_decoded_img = torch.cat(list_decoded_img)\n",
    "        list_img = torch.cat(list_img)\n",
    "        # print(list_img, list_decoded_img, \"vaLLLLL FUNCTION\")\n",
    "#         for i in range(len(list_img)):\n",
    "            \n",
    "        val_loss = loss_fn(list_decoded_img, list_img)\n",
    "    return val_loss.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "646ee6a1-b90a-48fb-b050-fc5d047680c3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#finding global normalization numbers for NR Curves\n",
    "import os\n",
    "directory = \"../\"\n",
    "totalDataY = []\n",
    "totalDataX = []\n",
    "count = 0\n",
    "for i,filename in enumerate(os.listdir(directory)):\n",
    "    f = os.path.join(directory, filename)\n",
    "    if os.path.isfile(f) and f[-3:] == \"npy\" and f[3:9] == \"NR-SLD\":\n",
    "        print(f[3:])\n",
    "        NRCurveY = np.load(f)[:,1]\n",
    "        NRCurveX = np.load(f)[:,0]\n",
    "        NRCurveY = np.log10(NRCurveY)\n",
    "        NRCurveX = np.log10(NRCurveX)\n",
    "        for j in range(len(NRCurveX)):\n",
    "            totalDataY.append(NRCurveY[j])\n",
    "            totalDataX.append(NRCurveX[j])\n",
    "        # totalDataY.append(NRCurveY)\n",
    "        # totalDataX.append(NRCurveX)\n",
    "min_valXNR = float('inf')\n",
    "max_valXNR = -float('inf')\n",
    "min_valYNR = float('inf')\n",
    "max_valYNR = -float('inf')\n",
    "totalDataY = np.array(totalDataY)\n",
    "totalDataX = np.array(totalDataX)\n",
    "# print(totalDataY.shape)\n",
    "for i in range(len(totalDataY)):\n",
    "    min_valXNR = min(min(totalDataX[i]), min_valXNR)\n",
    "    min_valYNR = min(min(totalDataY[i]), min_valYNR)\n",
    "    max_valXNR = max(max(totalDataX[i]), max_valXNR)\n",
    "    max_valYNR = max(max(totalDataY[i]), max_valYNR)\n",
    "# for i in range(len(totalDataY)):\n",
    "#     for j in range(len(totalDataY[0])):\n",
    "#         totalDataX[i][j] -= min_valXNR\n",
    "#         totalDataY[i][j] -= min_valYNR\n",
    "#         totalDataX[i][j] /= (max_valXNR - min_valXNR)\n",
    "#         totalDataY[i][j] /= (max_valYNR - min_valYNR)\n",
    "np.save(\"../NRRanges100000\", [min_valXNR, max_valXNR, min_valYNR, max_valYNR])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9718f4d3-02c8-40c1-b1a0-e1305b68cce9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#saving SLD ranges\n",
    "\n",
    "for first in range(1,6):\n",
    "        for second in range(1,6):\n",
    "            with open('SLDRanges'+str(first)+str(second)+'.npy', 'wb') as f:\n",
    "\n",
    "                curves_SLD = np.load('../SLD_CurvesPoly'+str(first)+str(second)+'.npy')\n",
    "\n",
    "                x_points = []\n",
    "                y_points = []\n",
    "                for curve in curves_SLD:\n",
    "                    x_points.append(curve[0])\n",
    "                    y_points.append(curve[1])\n",
    "                # breaker = 0\n",
    "                # # print(y_points[0])\n",
    "                # for i in range(1,len(y_points[0])):\n",
    "                #     if y_points[0][i]-y_points[0][i-1] != 0:\n",
    "                #         breaker = i\n",
    "                #         break\n",
    "                # print(breaker)\n",
    "                min_valX = float('inf')\n",
    "                min_valY = float('inf')\n",
    "                max_valX = -float('inf')\n",
    "                max_valY = -float('inf')\n",
    "                for i in range(len(y_points)):\n",
    "                    min_valX = min(min(x_points[i]), min_valX)\n",
    "                    min_valY = min(min(y_points[i]), min_valY)\n",
    "\n",
    "                    max_valX = max(max(x_points[i]), max_valX)\n",
    "                    max_valY = max(max(y_points[i]), max_valY)\n",
    "                np.save(f, np.array([min_valX, max_valX, min_valY, max_valY]))\n",
    "            # np.save(f, np.array([1, 3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ca56a58-16d9-488f-8226-ed67bfda3373",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0 509.10000000000724 -1.7698126020611056 5.396347352026074\n",
      "1 1\n",
      "xtrain.shape, ytrain.shape, xval.shape, yval.shape, xtest.shape, ytest.shape\n",
      "(90000, 1, 308) (90000, 2, 900) (5000, 1, 308) (5000, 2, 900) (5000, 1, 308) (5000, 2, 900)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 82\u001b[0m\n\u001b[1;32m     80\u001b[0m diz_loss \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain_loss\u001b[39m\u001b[38;5;124m'\u001b[39m:[],\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m'\u001b[39m:[]}\n\u001b[1;32m     81\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_epochs):\n\u001b[0;32m---> 82\u001b[0m     train_loss \u001b[38;5;241m=\u001b[39m \u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mModel\u001b[49m\u001b[43m,\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43moptim\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     83\u001b[0m     val_loss \u001b[38;5;241m=\u001b[39m val(Model,device,valid_loader,loss_fn)\n\u001b[1;32m     84\u001b[0m     diz_loss[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain_loss\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mappend(train_loss)\n",
      "Cell \u001b[0;32mIn[11], line 5\u001b[0m, in \u001b[0;36mfit\u001b[0;34m(Model, device, dataloader, loss_fn, optim)\u001b[0m\n\u001b[1;32m      3\u001b[0m Model\u001b[38;5;241m.\u001b[39mtrain()\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m      4\u001b[0m train_loss \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m----> 5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m data,label \u001b[38;5;129;01min\u001b[39;00m dataloader:\n\u001b[1;32m      6\u001b[0m     img \u001b[38;5;241m=\u001b[39m data\n\u001b[1;32m      7\u001b[0m     img \u001b[38;5;241m=\u001b[39m img\u001b[38;5;241m.\u001b[39mto(device)\n",
      "File \u001b[0;32m/global/common/software/nersc/pm-2022q4/sw/pytorch/2.0.1/lib/python3.9/site-packages/torch/utils/data/dataloader.py:629\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    628\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__next__\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m--> 629\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mrecord_function(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_profile_name):\n\u001b[1;32m    630\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    631\u001b[0m             \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    632\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n",
      "File \u001b[0;32m/global/common/software/nersc/pm-2022q4/sw/pytorch/2.0.1/lib/python3.9/site-packages/torch/autograd/profiler.py:492\u001b[0m, in \u001b[0;36mrecord_function.__enter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    491\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__enter__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 492\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrecord \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprofiler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_record_function_enter_new\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    493\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m/global/common/software/nersc/pm-2022q4/sw/pytorch/2.0.1/lib/python3.9/site-packages/torch/_ops.py:502\u001b[0m, in \u001b[0;36mOpOverloadPacket.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    497\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    498\u001b[0m     \u001b[38;5;66;03m# overloading __call__ to ensure torch.ops.foo.bar()\u001b[39;00m\n\u001b[1;32m    499\u001b[0m     \u001b[38;5;66;03m# is still callable from JIT\u001b[39;00m\n\u001b[1;32m    500\u001b[0m     \u001b[38;5;66;03m# We save the function ptr as the `op` attribute on\u001b[39;00m\n\u001b[1;32m    501\u001b[0m     \u001b[38;5;66;03m# OpOverloadPacket to access it here.\u001b[39;00m\n\u001b[0;32m--> 502\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_op\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#Training each model\n",
    "\n",
    "from copy import deepcopy\n",
    "count = 0\n",
    "for first in range(1,6):\n",
    "    for second in range(1,6):\n",
    "        count += 1\n",
    "        with open('../SLDRanges100000.npy', 'rb') as f:\n",
    "            min_valXSLD, max_valXSLD, min_valYSLD, max_valYSLD = np.load(f)\n",
    "        print(min_valXSLD, max_valXSLD, min_valYSLD, max_valYSLD)\n",
    "        loss_fn = torch.nn.MSELoss()\n",
    "        lr= 2.15481e-05\n",
    "        torch.manual_seed(0)\n",
    "        Model = CNN(num_layers=12)\n",
    "        params_to_optimize = Model.parameters()\n",
    "\n",
    "        optim = torch.optim.Adam(params_to_optimize, lr=lr, weight_decay= 2.6324e-05)\n",
    "        device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "        Model.to(device)\n",
    "        print(first, second)\n",
    "        curves_nr = np.load('../NR-SLD_CurvesPoly' + str(first) + str(second) + '.npy')\n",
    "        curves_SLD = np.load('../SLD_CurvesPoly' + str(first) + str(second) + '.npy')\n",
    "\n",
    "        curves_nr = np.log10(curves_nr)\n",
    "\n",
    "        x_points = []\n",
    "        y_points = []\n",
    "        for curve in curves_nr:\n",
    "            x_points.append(curve[0])\n",
    "            y_points.append(curve[1])\n",
    "        for i in range(len(y_points)):\n",
    "            for j in range(len(y_points[0])):\n",
    "                x_points[i][j] -= min_valXNR\n",
    "                y_points[i][j] -= min_valYNR\n",
    "                x_points[i][j] /= (max_valXNR - min_valXNR)\n",
    "                y_points[i][j] /= (max_valYNR - min_valYNR)\n",
    "        curves_nr2 = []\n",
    "        for i in range(len(y_points)):\n",
    "            curves_nr2.append([x_points[i],y_points[i]])\n",
    "        #     plt.plot(x_points[i], y_points[i])\n",
    "        # plt.show()\n",
    "        curves_nr2 = np.stack(curves_nr2)\n",
    "        curves_nr2.shape\n",
    "        x_points = []\n",
    "        y_points = []\n",
    "        for curve in curves_SLD:\n",
    "            x_points.append(curve[0].copy())\n",
    "            y_points.append(curve[1].copy())\n",
    "        min_valX = float('inf')\n",
    "        min_valY = float('inf')\n",
    "        max_valX = -float('inf')\n",
    "        max_valY= -float('inf')\n",
    "        for i in range(len(y_points)):\n",
    "            min_valX = min(min(x_points[i]), min_valX)\n",
    "            min_valY = min(min(y_points[i]), min_valY)\n",
    "            max_valX = max(max(x_points[i]), max_valX)\n",
    "            max_valY = max(max(y_points[i]), max_valY)\n",
    "        for i in range(len(y_points)):\n",
    "            for j in range(len(y_points[0])):\n",
    "                x_points[i][j] -= min_valX\n",
    "                y_points[i][j] -= min_valY\n",
    "                x_points[i][j] /= (max_valX - min_valX)\n",
    "                y_points[i][j] /= (max_valY - min_valY)\n",
    "        curves_SLD2 = []\n",
    "        for i in range(len(y_points)):\n",
    "            curves_SLD2.append([x_points[i],y_points[i]])\n",
    "        curves_SLD2 = np.stack(curves_SLD2)\n",
    "        curves_SLD2.shape\n",
    "        batch_size=32\n",
    "        R = curves_nr[:,1]\n",
    "\n",
    "        R_m = R[:,np.newaxis,:]\n",
    "        xtrain, ytrain, xval, yval, xtest, ytest = \\\n",
    "        dpre.split_input_arrays(R_m,curves_SLD2, size_split=0.9)\n",
    "        #Prepare data files, continuation\n",
    "        train_dataset, valid_dataset, test_dataset, train_loader, valid_loader, test_loader = \\\n",
    "        dpre.get_dataloaders_fromsplitarrays(xtrain,ytrain,xval,yval,xtest,ytest,batch_size=batch_size)\n",
    "        num_epochs=500\n",
    "        #train and validate\n",
    "        diz_loss = {'train_loss':[],'val_loss':[]}\n",
    "        for epoch in range(num_epochs):\n",
    "            train_loss = fit(Model,device,train_loader,loss_fn,optim)\n",
    "            val_loss = val(Model,device,valid_loader,loss_fn)\n",
    "            diz_loss['train_loss'].append(train_loss)\n",
    "            diz_loss['val_loss'].append(val_loss)\n",
    "            \n",
    "        torch.save(Model.state_dict(), \"../PolyzwitterionModels100000/ModelPoly100000\" + str(first)+str(second))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf2132ab-92a5-4123-b307-bf561bd289bf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch-2.0.1",
   "language": "python",
   "name": "pytorch-2.0.1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
