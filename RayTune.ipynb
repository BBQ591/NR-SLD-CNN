{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3fcec7e1-48c9-47ee-b2b3-9a83aeb3ab58",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fatal: destination path 'Neutron_Reflect' already exists and is not an empty directory.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/miguel-fc/Neutron_Reflect.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "483dccd5-6554-4fef-937e-1ec0d64990d1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/pscratch/sd/q/qubri000/Neutron_Reflect\n"
     ]
    }
   ],
   "source": [
    "cd Neutron_Reflect/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f65f831-02c4-4394-8ecf-079fa84968be",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install --upgrade pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c3c087d-ec58-454c-a9ab-e7e3e1ce7fe6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pip install ray==2.9.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43a0af05-f1d9-40f3-bc1a-c5c42cd74fe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install -U tensorboardx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b95d5d13-ff50-41c6-bdd3-ee1d5b757678",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pip install optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a923cd9-6cda-4588-afef-4b3f612a5234",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pip install fsspec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ac8abed-26db-4d08-b781-8dbd5224776d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pip install pyarrow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a67f2c5f-6f0e-4630-9cda-035a84737d42",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# pip install tensorboard==2.12.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9df4ee90-c29e-4945-a389-ceea3f55a1e3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# pip install -U protobuf==3.19.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e779cf8-dd4e-4bec-aa96-7a13d0e13827",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pip install gdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c89da939-70ee-4038-b9f0-f5e872c004d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58ee71cc-0023-4b5f-8ef9-99258978a404",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pip install -U ipywidgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b02edc6-4f2f-4118-8ed3-eb5322b05ce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install plotly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a8a0de76-6079-4998-8a7d-7dba6fa661fc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.datasets as datasets\n",
    "import numpy as np\n",
    "import data_preparation as dpre\n",
    "import io\n",
    "import os\n",
    "# import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.lines as mlines\n",
    "%matplotlib inline\n",
    "import seaborn as sea\n",
    "\n",
    "from ray import air, tune\n",
    "from ray.air import session\n",
    "from ray.tune.schedulers import ASHAScheduler\n",
    "from ray.air.checkpoint import Checkpoint\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "adadc327-ff32-48e9-bec4-3d9bdf9cbf87",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((50000, 2, 308), (50000, 2, 900))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Loading in NR and SLD curves\n",
    "\n",
    "\n",
    "curves_nr = np.load('../NR-SLD_CurvesPoly11.npy')\n",
    "curves_SLD = np.load('../SLD_CurvesPoly11.npy')\n",
    "curves_nr.shape, curves_SLD.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "958a7f29-ca13-4672-995a-78c66527f97a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#plot NR curves\n",
    "\n",
    "for x in range(curves_nr.shape[0]):\n",
    "  plt.plot(curves_nr[x][0],curves_nr[x][1])\n",
    "plt.xscale('log')\n",
    "plt.yscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fc1b445e-043a-4ba6-a7a6-ca7584bbcb79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 2, 308)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#normalize NR curves\n",
    "\n",
    "curves_nr = np.log10(curves_nr)\n",
    "\n",
    "x_points = []\n",
    "y_points = []\n",
    "for curve in curves_nr:\n",
    "    x_points.append(curve[0])\n",
    "    y_points.append(curve[1])\n",
    "min_valX = float('inf')\n",
    "min_valY = float('inf')\n",
    "max_valX = -float('inf')\n",
    "max_valY = -float('inf')\n",
    "for i in range(len(y_points)):\n",
    "    min_valX = min(min(x_points[i]), min_valX)\n",
    "    min_valY = min(min(y_points[i]), min_valY)\n",
    "    max_valX = max(max(x_points[i]), max_valX)\n",
    "    max_valY = max(max(y_points[i]), max_valY)\n",
    "for i in range(len(y_points)):\n",
    "    for j in range(len(y_points[0])):\n",
    "        x_points[i][j] -= min_valX\n",
    "        y_points[i][j] -= min_valY\n",
    "        x_points[i][j] /= (max_valX - min_valX)\n",
    "        y_points[i][j] /= (max_valY - min_valY)\n",
    "curves_nr2 = []\n",
    "for i in range(len(y_points)):\n",
    "    curves_nr2.append([x_points[i],y_points[i]])\n",
    "curves_nr2 = np.stack(curves_nr2)\n",
    "curves_nr2.shape\n",
    "# for x in range(curves_nr.shape[0]):\n",
    "#   plt.plot(curves_nr[x][0],curves_nr[x][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "538cbb1f-7762-461b-b302-30fb1c5e605c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#plot SLD curves\n",
    "\n",
    "for x in range(curves_nr.shape[0]):\n",
    "  plt.plot(curves_SLD[x][0],curves_SLD[x][1])\n",
    "# plt.xscale('log')\n",
    "# plt.yscale('log')\n",
    "print(curves_SLD[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a65d67d2-fa1c-4f29-a81f-422dfd246b19",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.         0.0007949  0.0015898  ... 0.71302488 0.71381978 0.71461468]\n",
      " [0.36503044 0.36503044 0.36503044 ... 0.08686069 0.08665173 0.08647615]]\n"
     ]
    }
   ],
   "source": [
    "#normalize SLD curves\n",
    "x_points = []\n",
    "y_points = []\n",
    "for curve in curves_SLD:\n",
    "    x_points.append(curve[0])\n",
    "    y_points.append(curve[1])\n",
    "min_valX = float('inf')\n",
    "min_valY = float('inf')\n",
    "max_valX = -float('inf')\n",
    "max_valY = -float('inf')\n",
    "for i in range(len(y_points)):\n",
    "    min_valX = min(min(x_points[i]), min_valX)\n",
    "    min_valY = min(min(y_points[i]), min_valY)\n",
    "    max_valX = max(max(x_points[i]), max_valX)\n",
    "    max_valY = max(max(y_points[i]), max_valY)\n",
    "for i in range(len(y_points)):\n",
    "    for j in range(len(y_points[0])):\n",
    "        x_points[i][j] -= min_valX\n",
    "        y_points[i][j] -= min_valY\n",
    "        x_points[i][j] /= (max_valX - min_valX)\n",
    "        y_points[i][j] /= (max_valY - min_valY)\n",
    "curves_SLD2 = []\n",
    "for i in range(5000):\n",
    "    curves_SLD2.append([x_points[i],y_points[i]])\n",
    "curves_SLD2 = np.stack(curves_SLD2)\n",
    "# for x in range(curves_nr.shape[0]):\n",
    "#   plt.plot(curves_SLD[x][0],curves_SLD[x][1])\n",
    "# plt.xscale('log')\n",
    "# plt.yscale('log')\n",
    "print(curves_SLD[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5785fc80-36d0-4c88-bdef-965590ec58f5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Make CNN class\n",
    "\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self, num_layers):\n",
    "        super(CNN, self).__init__()\n",
    "        self.layers = nn.ModuleList()\n",
    "        addition = 255/num_layers\n",
    "        curr = 1\n",
    "        for hdim in range(num_layers-1):\n",
    "            self.layers.append(nn.Conv1d(int(curr+0.5), int(curr+addition+0.5),51,padding=25))\n",
    "            self.layers.append(nn.BatchNorm1d(int(curr+addition+0.5)))\n",
    "            self.layers.append(nn.ReLU(True))\n",
    "            curr += addition\n",
    "        self.layers.append(nn.Conv1d(int(curr+0.5), 256, 51, padding=25))\n",
    "        self.linear1 = nn.Linear(256*308,2*308)\n",
    "    def forward(self, x):\n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "        x = x.reshape(x.shape[0], -1)\n",
    "        x = self.linear1(x)\n",
    "        x = x.reshape(-1, 2, 308)\n",
    "        return torch.sigmoid(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5c6e6013-464a-4ef2-8441-9d3e9e64207a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected device: cuda\n"
     ]
    }
   ],
   "source": [
    "### Define the loss function\n",
    "loss_fn = torch.nn.MSELoss()\n",
    "#learning rate\n",
    "lr= 0.00001\n",
    "\n",
    "### Set the random seed for reproducible results\n",
    "torch.manual_seed(0)\n",
    "\n",
    "#make CNN\n",
    "Model = CNN(num_layers=5)\n",
    "params_to_optimize = Model.parameters()\n",
    "\n",
    "optimizer = torch.optim.Adam(params_to_optimize, lr=lr, weight_decay=1e-5)\n",
    "# Check if the GPU is available\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "print(f'Selected device: {device}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d83dd25e-16a9-4819-bf60-c031f9d7cb4a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CNN(\n",
       "  (layers): ModuleList(\n",
       "    (0): Conv1d(1, 52, kernel_size=(51,), stride=(1,), padding=(25,))\n",
       "    (1): BatchNorm1d(52, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): Conv1d(52, 103, kernel_size=(51,), stride=(1,), padding=(25,))\n",
       "    (4): BatchNorm1d(103, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): ReLU(inplace=True)\n",
       "    (6): Conv1d(103, 154, kernel_size=(51,), stride=(1,), padding=(25,))\n",
       "    (7): BatchNorm1d(154, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (8): ReLU(inplace=True)\n",
       "    (9): Conv1d(154, 205, kernel_size=(51,), stride=(1,), padding=(25,))\n",
       "    (10): BatchNorm1d(205, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (11): ReLU(inplace=True)\n",
       "    (12): Conv1d(205, 256, kernel_size=(51,), stride=(1,), padding=(25,))\n",
       "  )\n",
       "  (linear1): Linear(in_features=78848, out_features=616, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5cf93dbe-e54a-4fc8-8a4a-edcbbf3afbaa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Training function\n",
    "def fit(Model, dataloader, loss_fn, optim):\n",
    "    device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "    Model.train().to(device)\n",
    "    train_loss = []\n",
    "    for data,label in dataloader:\n",
    "        img = data\n",
    "        img = img.to(device)\n",
    "        label = label.to(device)\n",
    "        decoded_img = Model(img)\n",
    "        # print(decoded_img.shape)\n",
    "        # decoded_img = decoded_img.reshape(-1,2, 308)\n",
    "        loss = loss_fn(decoded_img, label)\n",
    "        optim.zero_grad()\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "        train_loss.append(loss.cpu().detach().numpy())\n",
    "        # print(label, \"hello\")\n",
    "    return np.mean(train_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f2b82941-6f82-46ac-86cc-ad1f61d3a626",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "### Valid function\n",
    "def val(Model, dataloader, loss_fn):\n",
    "    device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "    Model.eval().to(device)\n",
    "    with torch.no_grad(): \n",
    "        list_decoded_img = []\n",
    "        list_img = []\n",
    "        for  data, label in dataloader:\n",
    "            img = data\n",
    "            # img = img.view(img.size(0), -1).to(device) \n",
    "            # img = img[:,np.newaxis,:].to(device) \n",
    "            img = img.to(device) \n",
    "            label = label.to(device)\n",
    "            decoded_img = Model(img)\n",
    "            # decoded_img = decoded_img.reshape(-1,2, 308)\n",
    "            list_decoded_img.append(decoded_img.cpu())\n",
    "            list_img.append(label.cpu())\n",
    "        list_decoded_img = torch.cat(list_decoded_img)\n",
    "        list_img = torch.cat(list_img)\n",
    "        # print(list_img, list_decoded_img, \"vaLLLLL FUNCTION\")\n",
    "#         for i in range(len(list_img)):\n",
    "            \n",
    "        val_loss = loss_fn(list_decoded_img, list_img)\n",
    "    return val_loss.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "11ee1e8f-0c34-4037-ae23-2646b3330cdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data split function\n",
    "\n",
    "def load_data(batch_size, size_split):\n",
    "    R = curves_nr[:5000,1]\n",
    "    R_m = R[:,np.newaxis,:]\n",
    "    # Q = curves_SLD[:,1]\n",
    "    # Q_m = Q[:, np.newaxis,:]\n",
    "    xtrain, ytrain, xval, yval, xtest, ytest = \\\n",
    "    dpre.split_input_arrays(R_m,curves_SLD2, size_split=size_split)\n",
    "    #Prepare data files, continuation\n",
    "    train_dataset, valid_dataset, test_dataset, train_loader, valid_loader, test_loader = \\\n",
    "    dpre.get_dataloaders_fromsplitarrays(xtrain,ytrain,xval,yval,xtest,ytest,batch_size=batch_size)\n",
    "\n",
    "    return train_loader, valid_loader, test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "51cf2c62-08e7-4b56-8f2e-144ac43aefb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xtrain.shape, ytrain.shape, xval.shape, yval.shape, xtest.shape, ytest.shape\n",
      "(4500, 1, 308) (4500, 2, 900) (250, 1, 308) (250, 2, 900) (250, 1, 308) (250, 2, 900)\n"
     ]
    }
   ],
   "source": [
    "train_loader, valid_loader, test_loader = load_data(32, 0.9)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "78fee56f-8250-4ad4-9261-0c9e7e33b2df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_cifar(config):\n",
    "    net = CNN(num_layers=config[\"num_layers\"])\n",
    "\n",
    "    device = \"cpu\"\n",
    "    if torch.cuda.is_available():\n",
    "        device = \"cuda:0\"\n",
    "        if torch.cuda.device_count() > 1:\n",
    "            net = nn.DataParallel(net)\n",
    "    net.to(device)\n",
    "\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = optim.Adam(net.parameters(), lr=config[\"lr\"], weight_decay=config[\"weight_decay\"])\n",
    "    # To restore a checkpoint, use `session.get_checkpoint()`.\n",
    "    loaded_checkpoint = session.get_checkpoint()\n",
    "    if loaded_checkpoint:\n",
    "        with loaded_checkpoint.as_directory() as loaded_checkpoint_dir:\n",
    "           model_state, optimizer_state = torch.load(os.path.join(loaded_checkpoint_dir, \"checkpoint.pt\"))\n",
    "        net.load_state_dict(model_state)\n",
    "        optimizer.load_state_dict(optimizer_state)\n",
    "\n",
    "    for epoch in range(10):  # loop over the dataset multiple times\n",
    "        running_loss = fit(net,  train_loader, criterion, optimizer)\n",
    "        # Validation loss\n",
    "        val_loss = val(net, valid_loader, criterion)\n",
    "\n",
    "        # Here we save a checkpoint. It is automatically registered with\n",
    "        # Ray Tune and can be accessed through `session.get_checkpoint()`\n",
    "        # API in future iterations.\n",
    "        os.makedirs(\"my_model\", exist_ok=True)\n",
    "        torch.save(\n",
    "            (net.state_dict(), optimizer.state_dict()), \"my_model/checkpoint.pt\")\n",
    "        checkpoint = Checkpoint.from_directory(\"my_model\")\n",
    "        session.report({\"loss\": (val_loss.item()), \"training loss\": running_loss}, checkpoint=checkpoint)\n",
    "    print(\"Finished Training\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b67fb857-ffb7-4fe8-af2b-2a7b8d2f5f99",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_best_model(best_result):\n",
    "    best_trained_model = CNN(num_layers=best_result.config[\"num_layers\"])\n",
    "    device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "    best_trained_model.to(device)\n",
    "\n",
    "    checkpoint_path = os.path.join(best_result.checkpoint.to_directory(), \"checkpoint.pt\")\n",
    "    \n",
    "    model_state, optimizer_state = torch.load(checkpoint_path)\n",
    "    best_trained_model.load_state_dict(model_state)\n",
    "\n",
    "    testLoss = val(best_trained_model, test_loader, loss_fn)\n",
    "\n",
    "\n",
    "    print(\"Best trial test set accuracy: {}\".format(testLoss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4066a6fe-ccdf-4ef7-9420-e85549ea7171",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/global/homes/q/qubri000/.local/perlmutter/pytorch2.0.1/lib/python3.9/site-packages/ray/air/config.py:803: UserWarning: Setting a `RunConfig.local_dir` is deprecated and will be removed in the future. If you are not using remote storage,set the `RunConfig.storage_path` instead. Otherwise, set the`RAY_AIR_LOCAL_CACHE_DIR` environment variable to control the local cache location.\n",
      "  warnings.warn(\n",
      "2024-03-12 18:09:31,965\tINFO worker.py:1621 -- Started a local Ray instance.\n"
     ]
    }
   ],
   "source": [
    "def main(num_samples=10, max_num_epochs=10, gpus_per_trial=1):\n",
    "    config = {\n",
    "    \"lr\": tune.loguniform(1e-5, 1e-3), \"weight_decay\": tune.loguniform(1e-5, 1e-3), \"num_layers\":tune.choice([14, 15,16,17,18])\n",
    "    }\n",
    "    scheduler = ASHAScheduler(\n",
    "        max_t=max_num_epochs,\n",
    "        grace_period=1,\n",
    "        reduction_factor=2)\n",
    "    \n",
    "    tuner = tune.Tuner(\n",
    "        tune.with_resources(\n",
    "            tune.with_parameters(train_cifar),\n",
    "            resources={\"cpu\": 1, \"gpu\": gpus_per_trial}\n",
    "        ),\n",
    "        tune_config=tune.TuneConfig(\n",
    "            metric=\"loss\",\n",
    "            mode=\"min\",\n",
    "            scheduler=scheduler,\n",
    "            num_samples=num_samples,\n",
    "        ),\n",
    "        param_space=config,\n",
    "        run_config=air.RunConfig(local_dir=\"$PSCRATCH\", name=\"test_experiment\")\n",
    "    )\n",
    "    results = tuner.fit()\n",
    "    best_result = results.get_best_result()\n",
    "\n",
    "    print(\"Best trial config: {}\".format(best_result.config))\n",
    "    print(\"Best trial final validation loss: {}\".format(\n",
    "        best_result.metrics[\"loss\"]))\n",
    "    print(\"Best trial final training loss: {}\".format(\n",
    "        best_result.metrics[\"training loss\"]))\n",
    "    test_best_model(best_result)\n",
    "\n",
    "main(num_samples=5, max_num_epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "637e21dd-a5da-4476-881a-5f10697e5456",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch-2.0.1",
   "language": "python",
   "name": "pytorch-2.0.1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
